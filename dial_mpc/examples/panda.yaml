# DIAL-MPC
# eimpty scene with no obstacle
seed: 0
output_dir: panda_bring_to_target
n_steps: 400

env_name: PandaRobot
Nsample: 2048
Hsample: 16
Hnode: 4
Ndiffuse: 2
Ndiffuse_init: 10
temp_sample: 0.05
horizon_diffuse_factor: 0.9
traj_diffuse_factor: 0.5
update_method: mppi

# Base environment
dt: 0.02
timestep: 0.02
action_scale: 0.04

# Panda-specific settings
reward_scales:
  gripper_box: 4.0
  box_target: 8.0
  no_floor_collision: 0.25
  robot_target_qpos: 0.3

# Simulation parameters
target_position_min: [-0.2, -0.2, 0.2]
target_position_max: [0.2, 0.2, 0.4]
box_position_min: [-0.2, -0.2, 0.0]
box_position_max: [0.2, 0.2, 0.0]


# Explanation:
# Top-Level Configuration:

# seed: Sets a random seed for reproducibility.
# output_dir: Directory where logs and outputs for the experiment will be saved.
# n_steps: Number of simulation steps for the experiment.
# Environment:

# env_name: Name of the Panda robot environment to use.
# Nsample, Hsample, Hnode, etc.: Parameters for sampling and optimization (copied from the Unitree Go2 example).
# Base Environment:

# dt: Simulation time step.
# timestep: Low-level MuJoCo simulation time step.
# action_scale: Scales the action to prevent jerky motions.
# Panda-Specific Settings:

# reward_scales: Defines the weighting for different reward terms specific to the Panda environment.
# Simulation Parameters:

# target_position_min and target_position_max: Defines the range for randomizing the target position.
# box_position_min and box_position_max: Defines the range for randomizing the box position.
# Save this file as panda_config.yaml and adjust values as needed for your specific task or environment tuning.